dirs:
    train:
        data: /data/sxu/easton/data/PTB/train
    dev:
        data: /data/sxu/easton/data/PTB/valid
    test:
        data: /data/sxu/easton/data/PTB/test
    type: csv
    vocab: /data/sxu/easton/data/PTB/vocab_2k.txt
    # restore: /data/sxu/easton/projects/EODM/models/timit_test/checkpoint

data:
    dim_embedding: 256
    unit: word

model:
    structure: lstm
    training_type: teacher-forcing
    loss_type: CE
    num_hidden: 256
    num_layers: 2

opti:
    type: adam
    warmup_steps: 100
    peak: 0.001
    decay_steps: 2000

dev_step: 50
decode_step: 200
save_step: 100

gpus: '0'
# gpus: '1,2,3'
batch_size: 400
num_batch_tokens: 10
bucket_boundaries: 20,30,40,50,60,70,80,90
num_epochs: 100000
num_steps: 500000
max_seq_len: 400

grad_clip_global_norm: 0.0
